<!DOCTYPE html>
<!--
==============================================================================
           "GitHub HTML5 Pandoc Template" v2.1 — by Tristano Ajmone           
==============================================================================
Copyright © Tristano Ajmone, 2017, MIT License (MIT). Project's home:

- https://github.com/tajmone/pandoc-goodies

The CSS in this template reuses source code taken from the following projects:

- GitHub Markdown CSS: Copyright © Sindre Sorhus, MIT License (MIT):
  https://github.com/sindresorhus/github-markdown-css

- Primer CSS: Copyright © 2016-2017 GitHub Inc., MIT License (MIT):
  http://primercss.io/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The MIT License 

Copyright (c) Tristano Ajmone, 2017 (github.com/tajmone/pandoc-goodies)
Copyright (c) Sindre Sorhus <sindresorhus@gmail.com> (sindresorhus.com)
Copyright (c) 2017 GitHub Inc.

"GitHub Pandoc HTML5 Template" is Copyright (c) Tristano Ajmone, 2017, released
under the MIT License (MIT); it contains readaptations of substantial portions
of the following third party softwares:

(1) "GitHub Markdown CSS", Copyright (c) Sindre Sorhus, MIT License (MIT).
(2) "Primer CSS", Copyright (c) 2016 GitHub Inc., MIT License (MIT).

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
==============================================================================-->
<html>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Julian Thukral, Julien Vitay and Fred Hamker" />
  <title>Forward models in the cerebellum</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="assets/github.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<article class="markdown-body">
<header>
<h1 class="title">Forward models in the cerebellum</h1>
<p class="author">Julian Thukral, Julien Vitay and Fred Hamker</p>
</header>
<p><strong>TODO:</strong> small abstract presenting the main idea (why forward models, cerebellum, etc) before jumping into the model.</p>
<p>For a human body to move accuratly, movement control solely based on sensory feedback would be too slow. The body would control the movement based on where it was and not where it is, resulting in movements that for example overshooting the target. It is believed that movement control is based on internal models predicting the future state of the body (or rather the future sensory feedback). The two internal models of motor control are the inverse model, which issues a motor command given the current state and the desired state of the body and the forward model which predicts the future state of the body given the current state and an efference copy of said motor command. The comparison between the predicted and the obtained state results in the prediction error, which again is used in motor control, motor learning and as a key component in generating a Sense of Agency. The Sense of Agency describes the experience of controlling our own actions and through them events in the outside world. Usually we don’t question if we are the agent of our own actions, it only comes into focus by the element of surprise when there is an incongruence of intention and action outcome. The cerebellum is thought to be the locus of the forward model. Acting not only as predictor of movements but also as the comparator between obtained and desired/predicted state. In this work we have built a neural forward model based on the architecture of the cerebellum. The model is trained to predict the future position of the hand of a 2D planar arm going in a circular motion.<br />
Furthermore we tested the capabilities of the model with an experiment based on the Random Dot Task.</p>
<p><br />
<br />
<br />
</p>
<h1 id="methods"><span class="header-section-number">1</span> Methods</h1>
<h2 id="description-of-the-model"><span class="header-section-number">1.1</span> Description of the model</h2>
<p>The proposed network is a reservoir computing model structurally inspired by the human cerebellum. Inputs from the cerebral cortex are fed through a intermediary layer into the reservoir via mossy fibers and to the output cells (projection neurons). A general hebbian algorithm (gha) layer is used as an intermediary step to decorrelate the input information before it is redirected to the reservoir.</p>
<p>The reservoir consists of randomly and recurrently connected neurons. It emulates the recurrent connectivity between granule cells (excitatory) and golgi cells (inhibitory), wich is able to exhibit strong non-linear dynamics.</p>
<p>The activity of the reservoir is read out by a layer of purkinje cells, which in turn inhibit the projection neurons (dentate nucleus neurons). The projection neurons fire rate functions as the model output on which basis the error is calculated. Based on the error feedback from the inferior olive cells synaptic weights are adjusted between the reservoir and the purkinje cell layer. The layers of the purkinje cells, inferior olive cells and the projection neurons consist of each one neuron for the x and y coordinate.</p>
<figure>
<img src="img/cb_model.png" alt="Figure 1: Structure of the model." class="center" /><figcaption><strong>Figure 1:</strong> Structure of the model.</figcaption>
</figure>
<p>The model is trained to predict the next position of the hand of a 2d arm ((<span class="math inline">\(x_{t+1}\)</span>, <span class="math inline">\(y_{t+1}\)</span>)) based on the current position ((<span class="math inline">\(x_{t}\)</span>, <span class="math inline">\(y_{t}\)</span>)) and a movement command in form of the <span class="math inline">\(\Delta\)</span> of the joint angles (<span class="math inline">\(\Delta\Theta_{elbow}\)</span> and <span class="math inline">\(\Delta\Theta_{shoulder}\)</span> ). The base of the arm is situated at the coordinate origin. Additionally, the input contains the information about the visual displacement from the last step to the current step i.e. (<span class="math inline">\(\Delta x = x_{t} - x_{t-1}\)</span>; <span class="math inline">\(\Delta y = y_{t} - y_{t-1}\)</span>).</p>
<figure>
<img src="img/arm.png" alt="Figure 2: 2D arm model. Source: doi:10.1109/IRIS.2017.8250090" class="center" /><figcaption><strong>Figure 2:</strong> 2D arm model. Source: doi:10.1109/IRIS.2017.8250090</figcaption>
</figure>
<p>The visual inputs correspond to positions on the target circle and not to predictions of the model. The current position of the hand at <span class="math inline">\(t+1\)</span> is represented by the target of timestep <span class="math inline">\(t\)</span> and not by the model prediction at <span class="math inline">\(t\)</span>. <span class="math inline">\(\Delta\Theta_{elbow}\)</span> and <span class="math inline">\(\Delta\Theta_{shoulder}\)</span> are calculated as the movement command from the last position on the target circle to the current position on the target circle. The same principle applies to the information about the last step i.e. <span class="math inline">\(\Delta x = x_t - x_{t-1} = x_{target_t-1}-x_{t-1}\)</span>. Keep in mind that <span class="math inline">\(x_t = x_{target_t-1}\)</span>.</p>
<p>The error is calculated as a normalized mean-square error (MSE) based on the difference between the predicted position (<span class="math inline">\(x_{t+1}\)</span>, <span class="math inline">\(y_{t+1}\)</span>) and the target (<span class="math inline">\(x_{target}\)</span>, <span class="math inline">\(y_{target}\)</span>).</p>
<p>Training is done using 100.000 circles, with 8 predictions/steps each. Each circle differentiates in the center of the circle, the radius, and the starting position of the hand in the circle. Each movement per timestep step was set to a movement of the hand of a constant 43 degrees. Thus each circle needed 8 steps for one complete circumnavigation.</p>
<figure>
<img src="img/training_plots/input_explanation.png" alt="Figure 3: The target moves 43 degrees in reference to the circle center. The target position of the hand at $x_{t+0} is used as the input of the current position of the hand at $x_{t+1}." style="width:50.0%" /><figcaption><strong>Figure 3:</strong> The target moves 43 degrees in reference to the circle center. The target position of the hand at $x_{t+0} is used as the input of the current position of the hand at $x_{t+1}.</figcaption>
</figure>
<h2 id="equations"><span class="header-section-number">1.2</span> Equations</h2>
<h3 id="neurons"><span class="header-section-number">1.2.1</span> Neurons</h3>
<p><strong>TODO:</strong> Make sentences and include all important equations.</p>
<p>The firerate of the input neurons was set to the desired input. There were six input neurons representing each of the six different input (x,y, <span class="math inline">\(\Delta\Theta_{elbow}\)</span>, <span class="math inline">\(\Delta\Theta_{shoulder}\)</span>, <span class="math inline">\(\Delta x\)</span>, <span class="math inline">\(\Delta y\)</span>).</p>
<p><br />
<br />
</p>
<p>The neurons of the gha layer can be cescribed with the following equation:</p>
<p><span class="math display">\[
\begin{aligned}r_{j} = \sum^i w_{ij}\, r_i \\\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(w_{ij}\)</span> represents the general hebbian algorithm pre-trained weights between input layer and gha layer and <span class="math inline">\(r_i\)</span> is given the connected input neuron.</p>
<p><br />
<br />
</p>
<p>The reservoir neurons follow a first-order ODEs:</p>
<p><span class="math display">\[
    \tau + \frac {dx(t)}{dt} + x(t)= \sum w^{in} \, r^{in}(t)+g
\]</span></p>
<p><span class="math inline">\(\tau = 10\)</span> meant the dynamics in the reservoir are relativly quick and the scaling factor <span class="math inline">\(g = 1\)</span> characterizes the strentgh of the recurrent connections in the reservoir at the edge of chaos, a base prequesite for an Echo State Reservoir. The weights <span class="math inline">\(w^{in}\)</span> are set using a random uniform distribution between the <span class="math inline">\(min=-0.5\)</span> and the <span class="math inline">\(max=0.5\)</span>, while <span class="math inline">\(r^{in}\)</span> is given by the firerrate of the gha pre-neuron.<br />
The activation function of the reservoir neurons was given as:</p>
<p><span class="math display">\[ 
r = tanh(x(t))
\]</span></p>
<p><br />
</p>
<p>The firing rate of the the Purkinje cell layer is not dynamic and described by:</p>
<p><span class="math display">\[
\begin{aligned}r_{j} = \sum^i w_{ij}\, r_i \\\end{aligned}
\]</span> The weights were initialized according to a normal distribution (<span class="math inline">\(m = 0\)</span> and <span class="math inline">\(\sigma = 0.1\)</span>) and updated each step using the learning rule.</p>
<p>The firerate of the Inferior olive neurons wich feed the error feedback to the Purkinje Cells is calculated and set in python each step.</p>
<p><br />
<br />
The projection neurons are defined by the similar equation as the prukinje cells: <span class="math display">\[
\begin{aligned}r_{j} = \sum^i w^{in}_{ij}\, I_i  - \sum^i w^{purk}_{ij}\, r_i \\\end{aligned}
\]</span></p>
<p>The projection neurons recieve a copy of the input from the mossy fibres and input from the purkinjie cells. <span class="math inline">\(w^{in}_{ij}\)</span> and <span class="math inline">\(w^{purk}_{ij}\)</span> are set to <span class="math inline">\(1\)</span>. The firerate of the projection neurons equals the copy of the mossy fibre input minus the purkinjie firerate. Hence the purkinjie cells don’t learn to predict the new coordinates of the hand of the arm but the movement between the old coordinates and the new.</p>
<h3 id="synapses"><span class="header-section-number">1.2.2</span> Synapses</h3>
<p><strong>TODO:</strong> GHA</p>
<p>Sanger’s rule aka Generalized Hebbian Algorithm <span class="math display">\[
\begin{aligned}\Delta w_{ij} =  \eta \, \bigg(y_i \, x_j - y_i \sum_{k=1}^i w_{kj} \, y_k\bigg)\\\end{aligned}
\]</span></p>
<p>Same rule in Matrix form.</p>
<p><span class="math display">\[
\begin{aligned}\Delta w_{(t)} =  \eta_{(t)} \, \bigg(y_{(t)} \, x_{(t)}^T - LT[y_{(t)} \, y_{(t)}^T] \, w_{(t)}\bigg) \\\end{aligned}
\]</span></p>
<p>Learning only happened in the synapses between the reservoir and the Purkinje cell layer and at the gha layer.</p>
<p>The gha layer</p>
<p>Weights are adjusted with a modified delta learning algorithm:</p>
<p><span class="math display">\[
\begin{aligned}\Delta w_{ij} =  \eta \, (r_{i} \, e_{j} - c \, w_{ij)}) \\\end{aligned}
\]</span></p>
<p>The learning rate was set to <span class="math inline">\(\eta = 0.005\)</span> . A cost parameter was added and set to <span class="math inline">\(c = 0.001\)</span>. Each step in the circle the error, <span class="math inline">\(e_j\)</span>, was calculated in python as target - model_prediction. And fed into the prukinje cell layer via the inferior olive cells.</p>
<h2 id="random-dot-task"><span class="header-section-number">1.3</span> Random dot task</h2>
<p>In the random dot task, the movement of the dot displayed on the monitor consists of the movement of the test subject and added noise. The ratio is specified by the control level, which defines the percentage of control a test subject has after the movement of the dot. To simulate a similar task for the model, a visual display circle is first calculated, based on the target circle with added noise. The added noise is taken from the same noise array as in the dot task, an array with prerecorded pseudorandom movements. At each step, a random movement in the array is taken, normalized and added to the movement of the target circle. The control level specifies the percentage of the movement done by noise or true movement.</p>
<p><strong>TODO</strong> make a figure to better explain.</p>
<p>This visual display is fed as input into the model. i.e.:</p>
<ul>
<li>the current position of the effector ((<span class="math inline">\(x_{t}\)</span>, <span class="math inline">\(y_{t})_{vd}\)</span>) is taken from the visual display and not from the target circle or the prediction of them model of the previous step.</li>
<li><span class="math inline">\(\Delta\Theta_{elbow}\)</span> and <span class="math inline">\(\Delta\Theta_{shoulder}\)</span> are calculated for the movement from (<span class="math inline">\(x_{t}\)</span>, <span class="math inline">\(y_{t})_{vd}\)</span> to the target on the target circle for current step</li>
<li><span class="math inline">\(\Delta x\)</span> and <span class="math inline">\(\Delta y\)</span> are based on the last movement by the visual display (<span class="math inline">\(\Delta x = (x_t - x_{t-1})_{vd}\)</span> ; <span class="math inline">\(\Delta y = (y_t - y_{t-1})_{vd}\)</span> )</li>
</ul>
<p>The condition in which the model is fed with the visual display will be called model agency condition. The error for each circle was calculated as mean square error.</p>
<p>Testing was conducted with 1000 trials without learning, starting with control level 0 and incrementing it by +0.001 each run. Each trial consists of 20 circles. Circles were created as in the training phase, differentiating in radius, circle center and starting position on the circle.</p>
<h1 id="results"><span class="header-section-number">2</span> Results</h1>
<h2 id="training"><span class="header-section-number">2.1</span> Training</h2>
<p>As can be seen in Fig. 2, the training MSE decreases rapidly during training, showing that learning the forward model of the arm is successful.</p>
<figure>
<img src="img/training_plots/training_Circle_0-100.png" alt="Figure 2: Training MSE of the first 100 Training Circles. MSE Circle 100 = 0.3177." style="width: 40%; margin: auto;" /><figcaption><strong>Figure 2:</strong> Training MSE of the first 100 Training Circles. MSE Circle 100 = 0.3177.</figcaption>
</figure>
<p>The following video illustrates how the model performance progresses through training. <strong>TODO: give more explanations on what should be observed.</strong></p>
<video controls width=60%>
<source src="./videos/training/training_circles_0-99999.mp4"
            type="video/mp4">
</video>
<h2 id="test-trials-with-different-control-levels"><span class="header-section-number">2.2</span> Test trials with different control levels</h2>
<p>Below are examplary videos of a test run. For each control level, 5 circles were run. The videos show the visual display and the movement of the model agency condition at the control levels 0.2, 0.5 and 0.7. The control level and the mse for the circle are displayed in the title.</p>
<p><strong>TODO:</strong> explain more what should be observed.</p>
<p><strong>Control level 0.2</strong></p>
<video controls width=60%>
<source src="./videos/test_only_ac_to_vd/test_video_cl_0.2.mp4"
            type="video/mp4">
</video>
<p><strong>Control level 0.5</strong></p>
<video controls width=60%>
<source src="./videos/test_only_ac_to_vd/test_video_cl_0.5.mp4"
            type="video/mp4">
</video>
<p><strong>Control level 0.7</strong></p>
<video controls width=60%>
<source src="./videos/test_only_ac_to_vd/test_video_cl_0.7.mp4"
            type="video/mp4">
</video>
<h2 id="relationship-between-the-control-level-and-the-prediction-error"><span class="header-section-number">2.3</span> Relationship between the control level and the prediction error</h2>
<p>Fig. 3 shows the influence of the control level on the prediction error (i.e. the MSE of the test circles raw values above, moving average below). As expected, the MSE increases as the control level decreases, signalling the discrepancy between the forward model predicting position and the noisy visual feedback. The sigmoidal shape of that relationship can be considered as a prediction of the model and confirmed experimentally.</p>
<figure>
<img src="img/test_plots/ED_from_model_ac_to_vd_cl_0-1.png" alt="Figure 3: Test MSE of Model Agency condition to Visual Display" style="width: 40%; margin: auto;" /><figcaption><strong>Figure 3:</strong> Test MSE of Model Agency condition to Visual Display</figcaption>
</figure>
</article>
</body>
</html>
